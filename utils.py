# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h5t-9vUt-ngJ2hTSgVJ7YnNIeNETzLNJ
"""

import torch
import torch.nn.functional as F

def loss_function(recon_x, x, mu, log_var):
    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')
    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())
    return BCE + KLD

def cycle(iterable):
    while True:
        for x in iterable:
            yield x

def get_latent_data(vae, dataloader, num_samples=2000):
    vae.eval()
    zs = []
    ys = []
    with torch.no_grad():
        for x, y in dataloader:
            x = x.to(CONFIG['device'])
            y_oh = F.one_hot(y, 10).float().to(CONFIG['device'])
            mu, log_var = vae.encoder(x.view(-1, 784), y_oh)
            z = vae.sampling(mu, log_var)
            zs.append(z.cpu().numpy())
            ys.append(y.numpy())
            if len(np.concatenate(zs)) > num_samples:
                break
    return np.concatenate(zs)[:num_samples], np.concatenate(ys)[:num_samples]